{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>281</td><td>application_1529568156751_0077</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hadoop30:8088/proxy/application_1529568156751_0077/\">Link</a></td><td><a target=\"_blank\" href=\"http://hadoop21:8042/node/containerlogs/container_e54_1529568156751_0077_01_000001/traffic_reginbald__jriv0000\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'2.3.0'"
     ]
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "month = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hdfs:///Projects/TrafficFlow/TrafficFlowParquet/TrafficFlowAll/Year=\" + str(year)+ \"/Month=\" + str(month) + \"/*.parquet\"\n",
    "df_raw = spark.read.parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      " |-- Minute: integer (nullable = true)\n",
      " |-- Road: string (nullable = true)\n",
      " |-- Km_Ref: integer (nullable = true)\n",
      " |-- Detector_Number: integer (nullable = true)\n",
      " |-- Traffic_Direction: short (nullable = true)\n",
      " |-- Flow_In: short (nullable = true)\n",
      " |-- Average_Speed: short (nullable = true)\n",
      " |-- Density: double (nullable = true)\n",
      " |-- Sign_Aid_Det_Comms: short (nullable = true)\n",
      " |-- Status: short (nullable = true)\n",
      " |-- Legend_Group: short (nullable = true)\n",
      " |-- Legend_Sign: short (nullable = true)\n",
      " |-- Legend_SubSign: short (nullable = true)\n",
      " |-- Protocol_Version: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---+---------+----+------+-----+------+---------------+-----------------+-------+-------------+------------------+------------------+------+------------+-----------+--------------+----------------+\n",
      "|          Timestamp|      Date|Day|DayOfWeek|Hour|Minute| Road|Km_Ref|Detector_Number|Traffic_Direction|Flow_In|Average_Speed|           Density|Sign_Aid_Det_Comms|Status|Legend_Group|Legend_Sign|Legend_SubSign|Protocol_Version|\n",
      "+-------------------+----------+---+---------+----+------+-----+------+---------------+-----------------+-------+-------------+------------------+------------------+------+------------+-----------+--------------+----------------+\n",
      "|2016-11-11 07:19:00|2016-11-11| 11|        5|   6|    19|  E4Z| 71400|              1|               78|     14|           93|  9.03225806451613|                 0|     3|         255|          1|             1|               4|\n",
      "|2016-11-11 23:52:00|2016-11-11| 11|        5|  22|    52|E265O|  1300|              2|               78|      1|           82|0.7317073170731707|                 0|     3|         255|          1|             1|               4|\n",
      "+-------------------+----------+---+---------+----+------+-----+------+---------------+-----------------+-------+-------------+------------------+------------------+------+------------+-----------+--------------+----------------+\n",
      "only showing top 2 rows"
     ]
    }
   ],
   "source": [
    "df_raw.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add node name\n",
    "@udf(StringType())\n",
    "def generate_node_id(road, km):\n",
    "    if km < 10:\n",
    "        return road + \"-000\" + str(km)[-3:]\n",
    "    if km < 100:\n",
    "        return road + \"-00\" + str(km)[-3:]\n",
    "    if km < 1000:\n",
    "        return road + \"-0\" + str(km)[-3:]\n",
    "    return road + \"-\" + str(km)[:-3] + \"\" + str(km)[-3:]\n",
    "\n",
    "df = df_raw.withColumn('node', generate_node_id('Road', 'Km_Ref'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861"
     ]
    }
   ],
   "source": [
    "#Check how many unique sensors are in the dataset\n",
    "df.select('node').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out errors/noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove error codes\n",
    "df_noise_free = df.where(col('Average_Speed') <= 250)\n",
    "\n",
    "# Only valid flow\n",
    "df_noise_free = df_noise_free.where(col('Flow_In') >= 0)\n",
    "df_noise_free = df_noise_free.where(col('Flow_In') <= 120)\n",
    "\n",
    "# limit speed to 120 km/h as it is used as the main speed limit on motorways\n",
    "# and we are only interested in average speed during heavy traffic\n",
    "df_noise_free = df.where(col('Average_Speed') <= 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827"
     ]
    }
   ],
   "source": [
    "#Check how many unique sensors are in the dataset\n",
    "df_noise_free.select('node').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|avg(Average_Speed)|\n",
      "+----+------------------+\n",
      "|   0| 80.90548804597815|\n",
      "|   1| 81.04797875979347|\n",
      "|   2| 81.00774697225984|\n",
      "|   3| 81.47937050497308|\n",
      "|   4| 82.07139191460804|\n",
      "|   5| 81.39414692002534|\n",
      "|   6| 75.06015491639732|\n",
      "|   7| 71.46532217664871|\n",
      "|   8| 71.81333782252806|\n",
      "|   9|  75.4109117880912|\n",
      "|  10| 76.34356304641476|\n",
      "|  11| 76.78323822376927|\n",
      "|  12| 76.02042489151845|\n",
      "|  13| 74.91951305958327|\n",
      "|  14| 73.26775500639778|\n",
      "|  15|  68.9119831966271|\n",
      "|  16| 63.81235366934743|\n",
      "|  17|  68.3766544717883|\n",
      "|  18| 75.12724527663848|\n",
      "|  19| 78.59904123635371|\n",
      "|  20| 79.56545950317044|\n",
      "|  21|  80.0564800108513|\n",
      "|  22| 80.54483259323759|\n",
      "|  23| 80.77500783923341|\n",
      "+----+------------------+"
     ]
    }
   ],
   "source": [
    "df_avg_speed = df_noise_free.select(hour(col('Timestamp')).alias('hour'), col('Average_Speed')) \\\n",
    "    .groupby(col('hour')).avg('Average_Speed') \\\n",
    "    .sort(col('hour'))\n",
    "    \n",
    "df_avg_speed.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use data between 7:00 to 8:00 and 14:00 to 17:00\n",
    "df_day_time = df_noise_free.select(\n",
    "    hour(col('Timestamp')).alias('hour'), \n",
    "    col('node'),\n",
    "    col('Average_Speed')\n",
    "    ).where(\"hour > 6 and hour < 18\") \\\n",
    "    .where(\"hour < 9 or hour > 13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|       node|     Average_Speed|\n",
      "+-----------+------------------+\n",
      "|E20_F-60630|  69.7245800616241|\n",
      "|E425N-58125|              53.5|\n",
      "| E18O-37735| 59.29376224689745|\n",
      "|  E6N-12920| 73.48458372263326|\n",
      "|E73_E-53135| 67.84747274529236|\n",
      "|  E75W-2840| 57.14751744963121|\n",
      "|  E75W-4370| 75.46368264529463|\n",
      "| E4_E-51430|50.770136211770755|\n",
      "|  E75O-0750| 43.70943768497205|\n",
      "|  E4N-28500|  90.6906728477686|\n",
      "|  E4N-32985| 93.12741493415335|\n",
      "|  E75W-1670|60.224579225176775|\n",
      "|  E4N-58480|58.936600276079666|\n",
      "|  E4N-59195| 66.73835629730254|\n",
      "| E182N-3285| 69.17095376700738|\n",
      "|  E75O-5180| 71.54878840869348|\n",
      "|  E4Z-38235| 74.08047991705138|\n",
      "| E4_A-64770| 50.68012256861178|\n",
      "|  E4Z-59205|57.883029141877586|\n",
      "|  E75O-5675| 72.46219833772822|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df_avg_speed = df_day_time.groupby(col('node')).avg('Average_Speed') \\\n",
    "    .select(col('node'), col('avg(Average_Speed)').alias('Average_Speed'))\n",
    "df_avg_speed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_speed.coalesce(1).write \\\n",
    "    .option('timestampFormat', 'yyyy-MM-dd HH:mm:ss.SSS') \\\n",
    "    .option('sep', ';') \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .mode('overwrite') \\\n",
    "    .save('hdfs:///Projects/traffic_reginbald/processed_traffic_data/avg_sensor_speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
